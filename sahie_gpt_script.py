import os
from openai import OpenAI
from dotenv import load_dotenv
import pandas as pd
import itertools
import json


load_dotenv()
print(os.environ.get("OPENAI_API_KEY"))

client = OpenAI(
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)

# FILE PATH for JSON
sahie_insights_path = "./data/sahie-insights.json"


def load_sahie_data():
    path = "./data/sahie-2022-csv/sahie_2022.csv"
    if os.path.exists(path):
        df = pd.read_csv(path, low_memory=False)
        df = df[df["geocat"] == 50].copy()
        df["fips"] = df["statefips"].astype(str).str.zfill(2) + df["countyfips"].astype(
            str
        ).str.zfill(3)
        df["PCTUI"] = pd.to_numeric(df["PCTUI"], errors="coerce")
        df = df.dropna(subset=["PCTUI"])
        return df
    return None


def generate_summary(sex, age, income, filtered_df):
    """
    Build an analytical insight prompt from filtered data and send it to GPT for summary generation.

    Parameters:
        filtered_df (pd.DataFrame): The filtered SAHIE data.
        sex (str): Selected sex filter.
        age (str): Selected age group filter.
        income (str): Selected income level filter.

    Returns:
        str: Insightful summary generated by the model.
    """
    # 1. National stats
    national_mean = round(filtered_df["PCTUI"].mean(), 2)
    national_median = round(filtered_df["PCTUI"].median(), 2)
    national_std = round(filtered_df["PCTUI"].std(), 2)
    total_counties = filtered_df["fips"].nunique()

    # 2. County-level outliers
    max_row = filtered_df.loc[filtered_df["PCTUI"].idxmax()]
    min_row = filtered_df.loc[filtered_df["PCTUI"].idxmin()]

    # 3. State-level trends
    state_summary = (
        filtered_df.groupby("state_name")
        .agg(avg_pctui=("PCTUI", "mean"))
        .sort_values("avg_pctui", ascending=False)
    )
    top_3_states = state_summary.head(3).round(2).reset_index()
    bottom_3_states = state_summary.tail(3).round(2).reset_index()

    # 4. Build prompt text
    prompt_text = f"""
You are a data analyst interpreting a choropleth map of U.S. counties showing uninsured percentages.

Demographic filters:
- Sex: {sex}
- Age Group: {age}
- Income Level: {income}
- Source: SAHIE 2022

National Summary:
- Mean Uninsured Rate: {national_mean}%
- Median: {national_median}% | Std Dev: {national_std}%
- Total Counties Analyzed: {total_counties}

Outliers:
- Highest Uninsured Rate: {max_row['county_name']}, {max_row['state_name']} – {round(max_row['PCTUI'], 2)}%
- Lowest Uninsured Rate: {min_row['county_name']}, {min_row['state_name']} – {round(min_row['PCTUI'], 2)}%

Top 3 States by Average Uninsured Rate:
{top_3_states.to_string(index=False)}

Bottom 3 States by Average Uninsured Rate:
{bottom_3_states.to_string(index=False)}

Write a plain English summary of the trends seen in the map:
- Describe regional patterns (e.g., high uninsured rates in the South).
- Mention standout counties or state-level differences.
- Do not include raw numbers or lists—write like a narrative summary.
(Max 75 words)
"""

    # 5. Send to OpenAI
    instructions = (
        "You are a skilled data analyst. "
        "Read the user's analysis prompt and write an insightful plain-English summary (max 75 words). "
        "Highlight regional trends, unusual outliers, and important disparities. "
        "Do not repeat statistics verbatim. Avoid raw data and lists—write like a policy-oriented report summary."
    )

    try:
        response = client.responses.create(
            model="gpt-4.1",
            instructions=instructions,
            input=prompt_text,
            temperature=0.3,
        )
        return response.output_text
    except Exception as e:
        return f"Error generating summary: {e}"


sahie_df = load_sahie_data()


sex_map = {0: "Both", 1: "Male", 2: "Female"}
age_map = {
    0: "Under 65",
    1: "18 to 64",
    2: "40 to 64",
    3: "50 to 64",
    4: "Under 19",
    5: "21 to 64",
}
income_map = {
    0: "All incomes",
    1: "≤ 200% poverty",
    2: "≤ 250%",
    3: "≤ 138%",
    4: "≤ 400%",
    5: "138% – 400%",
}

# Generate all filter combinations
combinations = list(
    itertools.product(sex_map.items(), age_map.items(), income_map.items())
)

with open(sahie_insights_path, "a+") as f:
    for (
        (sex_code, sex_label),
        (age_code, age_label),
        (income_code, income_label),
    ) in combinations:
        # Filter the dataframe
        filtered_df = sahie_df[
            (sahie_df["sexcat"] == sex_code)
            & (sahie_df["agecat"] == age_code)
            & (sahie_df["iprcat"] == income_code)
        ]

        if not filtered_df.empty:
            summary = (
                filtered_df.groupby("fips")
                .agg({"PCTUI": "mean", "county_name": "first", "state_name": "first"})
                .reset_index()
            )
            print("Shape: ", summary.shape)

            summary_dict = {}

            key = f"{sex_label} | {age_label} | {income_label}"

            print(f"\n=== {key} ===")
            print(summary.head(10).to_string(index=False))  # Print top 10 results
            summary_text = generate_summary(sex_label, age_label, income_label, summary)

            print(f"\nSummary for {key}: {summary_text}")
            summary_dict[key] = summary_text
            json.dump(summary_dict, f, indent=2)

        else:
            print(f"\n=== {sex_label} | {age_label} | {income_label} ===")
            print("No data found.")

        break

# response = client.responses.create(
#     model="gpt-3.5-turbo",
#     instructions="You are a coding assistant that talks like a pirate.",
#     input="How do I check if a Python object is an instance of a class?",
# )
#
# print(response.output_text)
